{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "from image_coder import ImageCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def int64_feature(value):\n",
    "    \"\"\"\n",
    "    Wrapper for inserting int64 features into Example proto:\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"\n",
    "    Wrapper for inserting bytes features into Example proto:\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def convert_to_example(filename, image_buffer, label_buffer, height, width):\n",
    "    \"\"\"\n",
    "    Build an Example proto for an example:\n",
    "    ----------\n",
    "    Args:\n",
    "        filename: string, path to an image file, e.g., '/path/to/example.png'\n",
    "        image_buffer: string, PNG encoding of RGB image\n",
    "        clss: integer, identifier for the ground truth for the network\n",
    "        height: integer, image height in pixels\n",
    "        width: integer, image width in pixels\n",
    "\n",
    "    Returns:\n",
    "            Example proto\n",
    "    \"\"\"\n",
    "\n",
    "    image_format = 'PNG'\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image/height': int64_feature(height),\n",
    "            'image/width': int64_feature(width),\n",
    "            'image/filename': bytes_feature(tf.compat.as_bytes(os.path.basename(os.path.normpath(filename)))),\n",
    "            'image/format': bytes_feature(tf.compat.as_bytes(image_format)),\n",
    "            'image/encoded/color': bytes_feature(tf.compat.as_bytes(image_buffer)),\n",
    "            'image/encoded/label': bytes_feature(tf.compat.as_bytes(label_buffer))\n",
    "            }))\n",
    "    return example\n",
    "\n",
    "\n",
    "def process_image(filename, coder):\n",
    "    \"\"\"\n",
    "    Process a single image file:\n",
    "    ----------\n",
    "    Args:\n",
    "        filename: string, path to an image file e.g., '/path/to/example.png'\n",
    "        coder: instance of ImageCoder to provide TensorFlow image coding utils\n",
    "\n",
    "    Returns:\n",
    "        image_buffer: string, PNG encoding of RGB image.\n",
    "        height: integer, image height in pixels.\n",
    "        width: integer, image width in pixels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the image file.\n",
    "    with tf.gfile.FastGFile(filename, 'r') as f:\n",
    "        image_data = f.read()\n",
    "\n",
    "    # Convert any JPEG to PNG for consistency\n",
    "    if coder.is_jpeg(filename):\n",
    "        print('[PROGRESS]\\tConverting JPEG to PNG for %s' % filename)\n",
    "        image_data = coder.jpeg_to_png(image_data)\n",
    "\n",
    "    # Decode the PNG\n",
    "    image = coder.decode_png(image_data)\n",
    "    print(\"Testing:\",image.shape[0],image.shape[1],image.shape[2])\n",
    "\n",
    "    # Check that image converted to RGB\n",
    "    assert len(image.shape) == 3\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "\n",
    "    # Check that color has 3 channels while depth, label just 1\n",
    "    if '_color' in filename:\n",
    "        assert image.shape[2] == 1\n",
    "    else:\n",
    "        assert image.shape[2] == 1\n",
    "\n",
    "    return image_data, height, width\n",
    "\n",
    "\n",
    "def process_image_files_batch(coder, thread_index, ranges, name, filenames, num_shards):\n",
    "    \"\"\"\n",
    "    Processes and saves list of images as TFRecord in 1 thread\n",
    "    ----------\n",
    "    Args:\n",
    "        coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "        thread_index: integer, unique batch to run index is within [0, len(ranges)).\n",
    "        ranges: list of pairs of integers specifying ranges of each batches to\n",
    "            analyze in parallel.\n",
    "        name: string, unique identifier specifying the data set\n",
    "        filenames: list of strings; each string is a path to an image file\n",
    "        num_shards: integer number of shards for this data set\n",
    "\n",
    "    # Each thread produces N shards where N = int(num_shards / num_threads).\n",
    "    # For instance, if num_shards = 128, and the num_threads = 2, then the first\n",
    "    # thread would produce shards [0, 64].\n",
    "    \"\"\"\n",
    "\n",
    "    num_threads = len(ranges)\n",
    "    assert not num_shards % num_threads\n",
    "    num_shards_per_batch = int(num_shards / num_threads)\n",
    "\n",
    "    shard_ranges = np.linspace(ranges[thread_index][0], ranges[thread_index][1],\n",
    "                               num_shards_per_batch + 1).astype(int)\n",
    "    num_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n",
    "\n",
    "    counter = 0\n",
    "    for s in xrange(num_shards_per_batch):\n",
    "\n",
    "        # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n",
    "        shard = thread_index * num_shards_per_batch + s\n",
    "        output_filename = '%s-%.5d-of-%.5d.tfrecords' % (name, shard, num_shards)\n",
    "        #output_file = os.path.join(FLAGS.output_dir, output_filename)\n",
    "        output_file = os.path.join('../../Datasets/training', output_filename)\n",
    "        writer = tf.python_io.TFRecordWriter(output_file)\n",
    "\n",
    "        shard_counter = 0\n",
    "        files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n",
    "        for i in files_in_shard:\n",
    "            filename = filenames[i]\n",
    "\n",
    "            # Concatenate naming conventions to get color, label true paths\n",
    "            color_file = filename % '_color'\n",
    "            label_file = filename % '_label'\n",
    "\n",
    "            image_buffer, height, width = process_image(color_file, coder)\n",
    "            label_buffer, height, width = process_image(label_file, coder)\n",
    "\n",
    "            example = convert_to_example(filename, image_buffer, label_buffer, height, width)\n",
    "            writer.write(example.SerializeToString())\n",
    "            shard_counter += 1\n",
    "            counter += 1\n",
    "\n",
    "        writer.close()\n",
    "        print('[THREAD %d]\\tWrote %d images to %s' %\n",
    "                    (thread_index, shard_counter, output_file))\n",
    "        shard_counter = 0\n",
    "\n",
    "    print('[THREAD %d]\\tWrote %d images to %d shards.' %\n",
    "                (thread_index, counter, num_files_in_thread))\n",
    "\n",
    "\n",
    "def process_image_files(name, filenames, num_shards):\n",
    "    \"\"\"\n",
    "    Process and save list of images as TFRecord of Example protos:\n",
    "    ----------\n",
    "    Args:\n",
    "        name: string, unique identifier specifying the data set\n",
    "        filenames: list of strings; each string is a path to an image file\n",
    "        num_shards: integer number of shards for this data set\n",
    "    \"\"\"\n",
    "\n",
    "    # Break all images into batches with a [ranges[i][0], ranges[i][1]].\n",
    "    spacing = np.linspace(0, len(filenames), FLAGS.num_threads + 1).astype(np.int)\n",
    "    ranges = []\n",
    "\n",
    "    for i in xrange(len(spacing) - 1):\n",
    "        ranges.append([spacing[i], spacing[i+1]])\n",
    "\n",
    "    # Launch a thread for each batch.\n",
    "    print('[PROGRESS]\\tLaunching %d threads for spacings: %s' % (FLAGS.num_threads, ranges))\n",
    "\n",
    "    # Create a mechanism for monitoring when all threads are finished.\n",
    "    coord = tf.train.Coordinator()\n",
    "\n",
    "    # Create a generic TensorFlow-based utility for converting all image codings.\n",
    "    coder = ImageCoder()\n",
    "\n",
    "    threads = []\n",
    "    for thread_index in xrange(len(ranges)):\n",
    "        args = (coder, thread_index, ranges, name, filenames, num_shards)\n",
    "        t = threading.Thread(target=process_image_files_batch, args=args)\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    # Wait for all the threads to terminate.\n",
    "    coord.join(threads)\n",
    "    print('[INFO    ]\\tFinished writing all %d images in data set.' % len(filenames))\n",
    "\n",
    "\n",
    "def find_image_files(data_dir):\n",
    "    \"\"\"\n",
    "    Build a list of all images files in the data set:\n",
    "    ----------\n",
    "    Args:\n",
    "        data_dir: string, path to the root directory of images. Assumes\n",
    "        (data_dir/image.png) format\n",
    "\n",
    "    Returns:\n",
    "        filenames: list of strings; each string is a path to an image file\n",
    "        following the format data_dir/image%s.png, %s will be replaced\n",
    "        with color, depth or annoation extension image_color.png\n",
    "    \"\"\"\n",
    "\n",
    "    print('[PROGRESS]\\tDetermining list of input files from %s' % data_dir)\n",
    "\n",
    "    filenames = []\n",
    "\n",
    "    # Construct the list of image files\n",
    "    color_file_path = os.path.join(data_dir, '*%s.*') % ('_color')\n",
    "    label_file_path = os.path.join(data_dir, '*%s.*') % ('_label')\n",
    "\n",
    "    color_files = tf.gfile.Glob(color_file_path)\n",
    "    label_files = tf.gfile.Glob(label_file_path)\n",
    "\n",
    "    assert len(color_files) == len(label_files)\n",
    "\n",
    "    matching_files = [ x.replace('_color', '%s') for x in color_files ]\n",
    "\n",
    "    filenames.extend(matching_files)\n",
    "\n",
    "    # Shuffle the ordering of all image files in order to guarantee randomness\n",
    "    shuffled_index = range(len(filenames))\n",
    "    random.seed(12345)\n",
    "    random.shuffle(shuffled_index)\n",
    "\n",
    "    filenames = [filenames[i] for i in shuffled_index]\n",
    "\n",
    "    print('[INFO    ]\\tFound %d images inside %s.' % (len(filenames), data_dir))\n",
    "\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def process_dataset(name, directory, num_shards):\n",
    "    \"\"\"\n",
    "    Process a complete data set and save it as a TFRecord\n",
    "    ----------\n",
    "    Args:\n",
    "        name: string, unique identifier specifying the data set\n",
    "        directory: string, root path to the data set\n",
    "        num_shards: integer number of shards for this data set\n",
    "    \"\"\"\n",
    "\n",
    "    filenames = find_image_files(directory)\n",
    "    process_image_files(name, filenames, num_shards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS]\tDetermining list of input files from ../../Datasets/training\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'FLAGS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-23c27dd9ae7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../Datasets/training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../../Datasets/training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-c4641e32fc6d>\u001b[0m in \u001b[0;36mprocess_dataset\u001b[0;34m(name, directory, num_shards)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \"\"\"\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_image_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0mprocess_image_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_shards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c4641e32fc6d>\u001b[0m in \u001b[0;36mfind_image_files\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# Construct the list of image files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mcolor_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*%s.*'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0mlabel_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*%s.*'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'FLAGS' is not defined"
     ]
    }
   ],
   "source": [
    "process_dataset(os.path.basename(os.path.normpath('../../Datasets/training')), '../../Datasets/training', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_file_path = os.path.join('../../Datasets/training', '*%s.*') % ('_color')\n",
    "label_file_path = os.path.join('../../Datasets/training', '*%s.*') % ('_label')\n",
    "color_files = tf.gfile.Glob(color_file_path)\n",
    "label_files = tf.gfile.Glob(label_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Datasets/training/4_color.png',\n",
       " '../../Datasets/training/2_color.png',\n",
       " '../../Datasets/training/5_color.png',\n",
       " '../../Datasets/training/3_color.png',\n",
       " '../../Datasets/training/1_color.png']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matching_files = [ x.replace('_color', '%s') for x in color_files ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Datasets/training/4%s.png',\n",
       " '../../Datasets/training/2%s.png',\n",
       " '../../Datasets/training/5%s.png',\n",
       " '../../Datasets/training/3%s.png',\n",
       " '../../Datasets/training/1%s.png']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = []\n",
    "filenames.extend(matching_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS]\tLaunching 1 threads for spacings: [[0, 5]]\n",
      "Testing: 615 2363 1\n",
      "Testing: 615 2363 1\n",
      "Testing: 1023 2259 1\n",
      "Testing: 1023 2259 1\n",
      "Testing: 867 2628 1\n",
      "Testing: 867 2628 1\n",
      "Testing: 1064 2417 1\n",
      "Testing: 1064 2417 1\n",
      "Testing: 1067 1510 1\n",
      "Testing: 1067 1510 1\n",
      "[THREAD 0]\tWrote 5 images to ../../Datasets/training/training-00000-of-00001.tfrecords\n",
      "[THREAD 0]\tWrote 5 images to 5 shards.\n",
      "[INFO    ]\tFinished writing all 5 images in data set.\n"
     ]
    }
   ],
   "source": [
    "#process_image_files\n",
    "name = os.path.basename(os.path.normpath('../../Datasets/training'))\n",
    "num_shards = 1\n",
    "spacing = np.linspace(0, len(filenames), 1 + 1).astype(np.int)\n",
    "ranges = []\n",
    "for i in xrange(len(spacing) - 1):\n",
    "    ranges.append([spacing[i], spacing[i+1]])\n",
    "print('[PROGRESS]\\tLaunching %d threads for spacings: %s' % (1, ranges))\n",
    "\n",
    "# Create a mechanism for monitoring when all threads are finished.\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "# Create a generic TensorFlow-based utility for converting all image codings.\n",
    "coder = ImageCoder()\n",
    "\n",
    "threads = []\n",
    "for thread_index in xrange(len(ranges)):\n",
    "    args = (coder, thread_index, ranges, name, filenames, num_shards)\n",
    "    t = threading.Thread(target=process_image_files_batch, args=args)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "# Wait for all the threads to terminate.\n",
    "coord.join(threads)\n",
    "print('[INFO    ]\\tFinished writing all %d images in data set.' % len(filenames))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
